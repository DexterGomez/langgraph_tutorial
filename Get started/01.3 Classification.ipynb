{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Tagging es el etiquetado a un documento en clases como:\n",
    "* sentimiento\n",
    "* idioma\n",
    "* estilo (formal, informal, etc.)\n",
    "* temas cubiertos\n",
    "* tendencias politicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Tagging tiene algunos componentes como:\n",
    "* function: Como en la extracción, tagging usa funciones para especificar como el modelo debería etiquetar el documento.\n",
    "* schema: define como se desea que se etiquete el documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pydantic es una librería para validación de datos en Python. Permite tener un control de que los datos se apeguen a una estructura especificada por el usuario.\n",
    "\n",
    "Aquí se especifica un modelo de Pydantic con propiedades y sus tipos de datos esperados en el esquema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(BaseModel):\n",
    "    sentimient: str = Field(description=\"The sentiment of the text\")\n",
    "    aggressiveness : int = Field(description=\"How aggressive the text is on a scale from 1 to 10\")\n",
    "    language: str = Field(description=\"The language the text is written in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\").with_structured_output(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentimient='positivo', aggressiveness=1, language='español')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\":text_input})\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos el diccionario de la salida, se puede llamar a la función .model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentimient': 'Enojo', 'aggressiveness': 8, 'language': 'Español'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": text_input})\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el modelo interpreta y clasifica la información correctamente. Sin embargo, los resultados varian mucho en sentido de que las clasificaciones hechas no siguen una estructura común (\"español\" vs \"Español\").\n",
    "\n",
    "Para solventar esta situación se presenta a continuación un metodo de control más ajustado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finer control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un control más especifico en el schema permite más control del output del modelo.\n",
    "\n",
    "Especificamente, se puede definir:\n",
    "* posibles valores para cada propiedad\n",
    "* descripciones para estar seguros de que el modelo entiende las propiedades\n",
    "* propiedades requeridas para ser retornadas\n",
    "\n",
    "Aquí se declara el schema usando Pydantric usando los aspectos mencionados para tener más control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(BaseModel):\n",
    "    sentiment:str = Field(enum=[\"happy\",\"neutral\",\"sad\",\"angry\"])\n",
    "    aggressiveness:int = Field(\n",
    "        description=\"describes how agressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1,2,3,4,5]\n",
    "    )\n",
    "    language:str = Field(\n",
    "        enum=[\"Spanish\",\"English\",\"French\",\"Chinese\",\"Italian\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "Only exttract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\").with_structured_output(Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora las respuestas deberían estar restringidas a las propiedades que hemos definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='sad', aggressiveness=4, language='Spanish')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = \"Estoy muy decepcionado de ti. Me gustaría nunca haberte conocido!\"\n",
    "prompt = tagging_prompt.invoke({\"input\":text_input})\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='angry', aggressiveness=4, language='English')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = \"I love how you are not getting what you want, you deserve all the struggiling you are having.\"\n",
    "prompt = tagging_prompt.invoke({\"input\":text_input})\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='neutral', aggressiveness=2, language='Spanish')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = \"Eres mi mejor amigo. But I hate you! - Said in a comic way\"\n",
    "prompt = tagging_prompt.invoke({\"input\":text_input})\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='happy', aggressiveness=1, language='Chinese')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = \"很高兴认识您！\"\n",
    "prompt = tagging_prompt.invoke({\"input\":text_input})\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
