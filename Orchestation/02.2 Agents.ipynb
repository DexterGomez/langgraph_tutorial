{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por si solos, los modelos de lenguaje no pueden realizar acciones, solo producir texto de salida. El uso de LangChain y LangGraph es la creación de agentes. Los agentes son sistemas que usan LLMs como motores de razonamiento que determinan que tareas realizar y que entradas son necesarias para completar la acción.\n",
    "\n",
    "Despues de que la acción sea completada, los resultados pueden ser usados para alimentar el contexto del LLM para determinar si más acciones son necesarias o ya esta completado todo lo requerido. Esto normalmente se logra con tool-calling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero es necesario crear las herramientas que deseamos usar. Aquí se presenta el uso de Tavily, un motor de busqueda.\n",
    "\n",
    "LangChain provee una herramienta para usar Tavily como una tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1741547954, 'localtime': '2025-03-09 12:19'}, 'current': {'last_updated_epoch': 1741547700, 'last_updated': '2025-03-09 12:15', 'temp_c': 13.9, 'temp_f': 57.0, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 4.9, 'wind_kph': 7.9, 'wind_degree': 220, 'wind_dir': 'SW', 'pressure_mb': 1023.0, 'pressure_in': 30.2, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 49, 'cloud': 50, 'feelslike_c': 13.6, 'feelslike_f': 56.5, 'windchill_c': 10.1, 'windchill_f': 50.1, 'heatindex_c': 10.7, 'heatindex_f': 51.2, 'dewpoint_c': 8.4, 'dewpoint_f': 47.2, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 3.9, 'gust_mph': 6.1, 'gust_kph': 9.9}}\"}, {'url': 'https://world-weather.info/forecast/usa/san_francisco/march-2025/', 'content': \"Weather in San Francisco in March 2025 (California) - Detailed Weather Forecast for a Month Weather in San Francisco Weather in San Francisco in March 2025 San Francisco Weather Forecast for March 2025 is based on long term prognosis and previous years' statistical data. 1 +54°+52° 2 +54°+50° 3 +54°+50° 4 +54°+48° 5 +61°+46° +59°+50° +59°+50° +61°+50° +61°+52° +61°+52° +63°+52° +63°+52° +61°+52° +61°+52° +63°+54° +61°+52° +63°+50° +61°+52° +61°+52° +59°+52° +61°+52° +59°+50° +57°+50° +57°+50° +59°+50° +59°+50° +61°+52° +63°+52° +63°+54° +63°+52° +63°+54° Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in Washington, D.C.+32° Sacramento+55° Pleasanton+52° Redwood City+55° San Leandro+55° San Mateo+54° San Rafael+55° San Ramon+52° South San Francisco+54° Vallejo+54° Palo Alto+55° Pacifica+55° Berkeley+57° Castro Valley+54° Concord+54° Daly City+54° Lagunitas+55° world's temperature today day day Temperature units\"}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "search_results = search.invoke(\"What is the weather in SF\")\n",
    "\n",
    "print(search_results)\n",
    "\n",
    "\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para permitir al modelo realizar tool caling, debemos usar .bind_tools para dar conocimiento al modelo de las herramientas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora llamaremos al modelo con la tool. Primero se llama al modelo con un mensaje normal; se pueden leer los campos content y tool_calls del response para ver como el modelo con la tool reacciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora haremos una prompt donde sí esperariamos que el modelo responda haciendo uso de la tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'weather in CDMX'}, 'id': 'call_djFcofJxFhj6u4ZHWBWFthwl', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in CDMX?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que no hay texto alguno en el contenido pero sí hubo una llamada a la tool. El modelo quiere hacer uso de la tool.\n",
    "\n",
    "Este codigo no esta haciendo uso de la herramienta aún, solo nos esta diciendo que quiere hacer uso de esta. Para poder usarla/llamarla, debemos definir el agente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya hemos declarado el modelo y la tool, ya podemos crear nuestro agente. Haremos uso de LangGraph para construir el agente. Se hara uso de una interfaz de alto nivel para construir el agente, las ventajas de LangGraph es que esta intefaz de alto nive esta hecha sobre bases de bajo nivel, bastante controlables con su API, y que permiten modificaciones en caso de que sea requerido.\n",
    "\n",
    "Ahora podemos inicializar el agente con el LLM y sus tools.\n",
    "\n",
    "Podrás notar que estamos pasando el model, no model_with_tools. Esto es porque create_react_agent llamará a .bind_tools por debajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se puede ejecutar el agente, pero hay que tomar en cuenta que son stateless, por lo que no preservan el historial de conversaciones. Nota que el agente retorna el estado final al final de la interacción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='4308a118-b4ef-459d-a9c8-b78cb66888f3'),\n",
       " AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 82, 'total_tokens': 93, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6fa9d972-56f1-4214-a433-61a60b5c0426-0', usage_metadata={'input_tokens': 82, 'output_tokens': 11, 'total_tokens': 93, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\":[HumanMessage(content=\"hi\")]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora observemos un ejemplo donde se haga el llamado a la tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"What's the weather in CDMX?\", additional_kwargs={}, response_metadata={}, id='9e1b5654-da40-4fe9-aa67-d7c747be792a'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kiQowCtZAxEriViOEVdu2hxf', 'function': {'arguments': '{\"query\":\"weather in CDMX\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 90, 'total_tokens': 113, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-263514c2-6c59-4e2f-a2ef-f15f202a218c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in CDMX'}, 'id': 'call_kiQowCtZAxEriViOEVdu2hxf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 90, 'output_tokens': 23, 'total_tokens': 113, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'error\\': {\\'code\\': 1006, \\'message\\': \\'No matching location found.\\'}}\"}, {\"url\": \"https://www.metcheck.com/WEATHER/dayforecast.asp?location=Mexico+City&locationID=2434396&lat=19.4&lon=-99.1&dateFor=09/03/2025\", \"content\": \"Weather Forecast for Mexico City for Sunday 9 March ; 0:00, 16 °c ; 3:00, 13 °c ; 6:00, 12 °c ; 9:00, 17 °c ; 12:00, 22 °c\"}]', name='tavily_search_results_json', id='41a63213-8e70-40d8-b70a-c7a5356976a5', tool_call_id='call_kiQowCtZAxEriViOEVdu2hxf', artifact={'query': 'weather in CDMX', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in CDMX', 'url': 'https://www.weatherapi.com/', 'content': \"{'error': {'code': 1006, 'message': 'No matching location found.'}}\", 'score': 0.828186, 'raw_content': None}, {'url': 'https://www.metcheck.com/WEATHER/dayforecast.asp?location=Mexico+City&locationID=2434396&lat=19.4&lon=-99.1&dateFor=09/03/2025', 'title': 'Weather Forecast for Mexico City for Sunday 9 March - Metcheck.com', 'content': 'Weather Forecast for Mexico City for Sunday 9 March ; 0:00, 16 °c ; 3:00, 13 °c ; 6:00, 12 °c ; 9:00, 17 °c ; 12:00, 22 °c', 'score': 0.7890553, 'raw_content': None}], 'response_time': 1.35}),\n",
       " AIMessage(content='The weather forecast for Mexico City (CDMX) for Sunday, 9th March is as follows:\\n- 00:00: 16°C\\n- 03:00: 13°C\\n- 06:00: 12°C\\n- 09:00: 17°C\\n- 12:00: 22°C\\n\\nFor more detailed information, you can visit [this link](https://www.metcheck.com/WEATHER/dayforecast.asp?location=Mexico+City&locationID=2434396&lat=19.4&lon=-99.1&dateFor=09/03/2025).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 280, 'total_tokens': 414, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9040258e-4418-43b0-9798-052f09d4db80-0', usage_metadata={'input_tokens': 280, 'output_tokens': 134, 'total_tokens': 414, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What's the weather in CDMX?\")]}\n",
    ")\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, el modelo retorna toda la respuesta una vez esta sea inferida. Usando tecnicas de streamming se puede lograr devolver las partes del output final mientras este se va procesando.\n",
    "\n",
    "Un metodo es stremeando los mensajes conforme se vayan produciendo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the weather in Boston?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_5BG05baFpKQ2sTdOyVmyzvTt)\n",
      " Call ID: call_5BG05baFpKQ2sTdOyVmyzvTt\n",
      "  Args:\n",
      "    query: weather in Boston\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'Boston', 'region': 'Massachusetts', 'country': 'United States of America', 'lat': 42.3583, 'lon': -71.0603, 'tz_id': 'America/New_York', 'localtime_epoch': 1741546953, 'localtime': '2025-03-09 15:02'}, 'current': {'last_updated_epoch': 1741546800, 'last_updated': '2025-03-09 15:00', 'temp_c': 6.7, 'temp_f': 44.1, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 13.0, 'wind_kph': 20.9, 'wind_degree': 259, 'wind_dir': 'W', 'pressure_mb': 1007.0, 'pressure_in': 29.74, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 33, 'cloud': 75, 'feelslike_c': 3.1, 'feelslike_f': 37.6, 'windchill_c': 2.3, 'windchill_f': 36.1, 'heatindex_c': 6.2, 'heatindex_f': 43.1, 'dewpoint_c': -3.2, 'dewpoint_f': 26.3, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 1.9, 'gust_mph': 15.7, 'gust_kph': 25.3}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/boston/march-2025/\", \"content\": \"Weather in Boston in March 2025 (Massachusetts) - Detailed Weather Forecast for a Month Weather World United States Weather in Boston Weather in Boston in March 2025 Boston Weather Forecast for March 2025, is based on previous years' statistical data. +39°+30° +41°+34° +41°+34° +39°+32° +43°+34° +41°+34° +43°+36° +43°+36° +45°+36° +45°+36° +46°+37° +46°+39° +45°+37° +46°+37° +45°+36° +43°+34° +48°+37° +46°+39° +43°+36° +48°+36° +45°+37° +46°+37° +48°+39° +43°+36° +45°+37° +46°+37° +46°+37° +46°+37° +48°+41° +50°+41° +50°+41° Extended weather forecast in Boston HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in Washington, D.C.+39° Newton+36° Peabody+37° Quincy+36° Somerville+37° South Boston+37° Wakefield+37° Waltham+36° Westford+36° Natick+37° Malden+37° Lynn+37° Beverly+37° Brockton+37° Brookline+37° Cambridge+37° Braintree+36° Melrose+37° world's temperature today day day Copyright © 2025 «World-Weather.info» All rights reserved. Temperature units\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current weather in Boston is partly cloudy with a temperature of 44.1°F (6.7°C). The wind is coming from the west at 20.9 km/h, and the humidity is at 33%.\n"
     ]
    }
   ],
   "source": [
    "for step in agent_executor.stream(\n",
    "    {\"messages\":[HumanMessage(content=\"What's the weather in Boston?\")]},\n",
    "     stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativo a stremmear mensajes, se pueden stremear tokens. Esto se puede lograr especificando stream_mode=\"messages\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The| current| weather| in| San| Francisco| is| as| follows|:\n",
      "|-| Temperature|:| |55|.|0|°F| (|12|.|8|°C|)\n",
      "|-| Condition|:| Part|ly| cloudy|\n",
      "|-| Wind|:| |4|.|9| mph|,| coming| from| the| southwest|\n",
      "|-| Pressure|:| |30|.|2| in|\n",
      "|-| Hum|idity|:| |64|%\n",
      "|-| Cloud| Cover|:| |50|%\n",
      "|-| Fe|els| like|:| |54|.|2|°F|\n",
      "|-| Visibility|:| |9|.|0| miles|\n",
      "\n",
      "|For| more| detailed| weather| forecast| information|,| you| can| visit| [|Weather|Api|.com|](|https|://|www|.weather|api|.com|/)| or| [|World|-|Weather|.info|](|https|://|world|-|weather|.info|/|forecast|/|usa|/s|an|_fr|anc|isco|/m|arch|-|202|5|/|).|"
     ]
    }
   ],
   "source": [
    "for step, metadata in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):\n",
    "        print(text, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El agente es stateless por lo que no tiene memoria de las conversaciones. Para darle memoria debemos proveerle un checkpointer junto con thread_id al hacer .invoke del modelo, para ir guardado la conversación y que el modelo tenga memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\":{\"thread_id\":\"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 85, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dc936e26-3884-4bf1-89f2-feddcd804734-0', usage_metadata={'input_tokens': 85, 'output_tokens': 12, 'total_tokens': 97, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Your name is Bob! How may I assist you further, Bob?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 108, 'total_tokens': 124, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4564bf5e-3f06-4270-85ea-c4482c4efc97-0', usage_metadata={'input_tokens': 108, 'output_tokens': 16, 'total_tokens': 124, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
